{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "teasers = []\n",
    "tweets = []\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "news_title = \"\"\n",
    "news_p = \"\"\n",
    "mars_weather = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "\n",
    "soup = bs(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NASA Social Media and Websites Win Webby Awards :\n",
      "\n",
      "NASA's social media presence, the InSight mission social media accounts, NASA.gov and SolarSystem.NASA.gov will be honored at the 2019 Webby Awards - \"the Oscars of the Internet.\"\n"
     ]
    }
   ],
   "source": [
    "load = \"y\"\n",
    "\n",
    "while load == \"y\":\n",
    "\n",
    "    if(browser.is_element_present_by_tag(\"ul\", wait_time=5)):\n",
    "        \n",
    "        load = \"n\"\n",
    "\n",
    "        results = soup.find_all('div', class_='list_text')\n",
    "\n",
    "        for result in results:\n",
    "            try:\n",
    "                title = result.find('a').text\n",
    "                titles.append(title)\n",
    "            except ElementDoesNotExist:\n",
    "                print(\"Child tag <a> does not exist or does not have valid text.\")\n",
    "\n",
    "            try:\n",
    "                teaser = result.find(\"div\", class_=\"article_teaser_body\").text\n",
    "                teasers.append(teaser)\n",
    "            except ElementDoesNotExist:\n",
    "                print(\"Child tag <div, class='article_teaser_body'> does not exist or does not have valid text.\")\n",
    "                \n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"Parent Element <ul> Not Found. The webpage has either changed or hasn't completed loading.\")\n",
    "        load = input(\"Try again: y/n?\").lower()[0]\n",
    "        \n",
    "print(f\"\\n{titles[0]}:\")\n",
    "print(f\"\\n{teasers[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "\n",
    "try:\n",
    "    browser.visit(url)\n",
    "except:\n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featured image url: https://photojournal.jpl.nasa.gov/jpeg/PIA08813-hi-res.jpg\n"
     ]
    }
   ],
   "source": [
    "load = \"y\"\n",
    "\n",
    "while load == \"y\":\n",
    "\n",
    "    if(browser.is_element_present_by_id(\"page\", wait_time=5)):\n",
    "\n",
    "        load =\"n\"\n",
    "        \n",
    "        try:\n",
    "            browser.click_link_by_id('full_image')\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(\"id: 'full_image' was not found.\")\n",
    "\n",
    "        try:\n",
    "            browser.click_link_by_partial_text('more info')\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(\"'more info' tab was not found.\")\n",
    "\n",
    "        try:\n",
    "            browser.click_link_by_partial_href('//photojournal.jpl.nasa.gov/jpeg/')\n",
    "            featured_image_url = browser.url\n",
    "            print(f'Featured image url: {featured_image_url}')\n",
    "        except:\n",
    "            print(\"full_image.jpg was not found.\")\n",
    "    else:\n",
    "        print(\"id: 'page' Not Found. The webpage has either changed or hasn't completed loading.\")\n",
    "        load = input(\"Try again: y/n?\").lower()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "try:\n",
    "    browser.visit(url)\n",
    "except:\n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InSight sol 147 (2019-04-26) low -98.4ºC (-145.2ºF) high -23.5ºC (-10.3ºF)\n",
      "winds from the W at 3.7 m/s (8.3 mph) gusting to 11.7 m/s (26.2 mph)\n",
      "pressure at 7.40 hPa pic.twitter.com/nZJCvAtZpU\n"
     ]
    }
   ],
   "source": [
    "load = \"y\"\n",
    "\n",
    "while load == \"y\":\n",
    "\n",
    "    if(browser.is_element_present_by_tag(\"ol\", wait_time=5)):\n",
    "        \n",
    "        load = \"n\"\n",
    "        results = soup.find_all('div', class_='js-tweet-text-container')\n",
    "\n",
    "        for result in results:\n",
    "            try:\n",
    "                tweet = result.find('p').text\n",
    "                \n",
    "                if 'InSight sol' in tweet:\n",
    "                    tweets.append(tweet.replace(\"hPa\", \"hPa \"))\n",
    "                    \n",
    "            except ElementDoesNotExist:\n",
    "                print(\"Child tag <p> does not exist or does not have valid text.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Parent Element <ol> Not Found. The webpage has either changed or hasn't completed loading.\")\n",
    "        load = input(\"Try again: y/n?\").lower()[0]\n",
    "\n",
    "ur1 = \"https://thumbs.gfycat.com/ExcitableSeveralAlligator-small.gif\"\n",
    "print(f\"\\n{tweets[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://space-facts.com/mars/\"\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "try:\n",
    "    browser.visit(url)\n",
    "except:\n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    browser.visit(url)\n",
    "\n",
    "table = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe table table-striped\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th></th>\n",
      "      <th>Value</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Property</th>\n",
      "      <th></th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>Equatorial Diameter:</th>\n",
      "      <td>6,792 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Polar Diameter:</th>\n",
      "      <td>6,752 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Mass:</th>\n",
      "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Moons:</th>\n",
      "      <td>2 (Phobos &amp; Deimos)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Orbit Distance:</th>\n",
      "      <td>227,943,824 km (1.52 AU)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Orbit Period:</th>\n",
      "      <td>687 days (1.9 years)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Surface Temperature:</th>\n",
      "      <td>-153 to 20 °C</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>First Record:</th>\n",
      "      <td>2nd millennium BC</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Recorded By:</th>\n",
      "      <td>Egyptian astronomers</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "string = io.StringIO()\n",
    "facts_df = pd.DataFrame({\"Property\": table[0][0], \"Value\": table[0][1]})\n",
    "facts = facts_df.set_index(\"Property\").to_html(buf=string, classes='table table-striped')\n",
    "facts = string.getvalue()\n",
    "print(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "try:\n",
    "    browser.visit(url)\n",
    "except:\n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cerberus Hemisphere \n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg\n",
      "Schiaparelli Hemisphere \n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg\n",
      "Syrtis Major Hemisphere \n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg\n",
      "Valles Marineris Hemisphere \n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg\n"
     ]
    }
   ],
   "source": [
    "load = \"y\"\n",
    "\n",
    "while load == \"y\":\n",
    "\n",
    "    if(browser.is_element_present_by_tag(\"section\", wait_time=5)):\n",
    "        \n",
    "        load = \"n\"\n",
    "        \n",
    "        results = soup.find_all('div', class_='item') \n",
    "        counter = -1\n",
    "\n",
    "        for result in results:\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            try:\n",
    "                time.sleep(4)\n",
    "                names = soup.find_all('h3')\n",
    "                name = names[counter].get_text().rstrip(\"Enhanced\")\n",
    "                print(name)\n",
    "                browser.find_by_tag(\"h3\")[counter].click()\n",
    "                \n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                print(\"<h3> element was not found.\")\n",
    "                \n",
    "                \n",
    "            try:\n",
    "                \n",
    "                html2 = browser.html\n",
    "                soup2 = bs(html2, 'html.parser')\n",
    "                new_url = soup2.find(\"a\", string=\"Sample\").get('href')\n",
    "                browser.visit(new_url)\n",
    "                img_url = browser.url\n",
    "                print(img_url)\n",
    "                time.sleep(2)\n",
    "                browser.back()\n",
    "                time.sleep(2)\n",
    "                browser.back()\n",
    "                hemisphere_image_urls.append({\"title\": name, \"img_url\": img_url})\n",
    "            except:\n",
    "                print(\"{a: text= 'Sample'} element was not found.\")\n",
    "                break\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(\"Parent Element <section> Not Found. The webpage has either changed or hasn't completed loading.\")\n",
    "        load = input(\"Try again: y/n?\").lower()[0]\n",
    "browser.visit(ur1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title = titles[0]\n",
    "news_p = teasers[0]\n",
    "mars_weather = tweets[0]\n",
    "hemisphere_image_urls = hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(15)\n",
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
